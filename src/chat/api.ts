import type { FlatMessage, DeepSeekStreamResponse, AIConfig, ChatMode } from './types'

// DeepSeek API é…ç½®
const API_BASE_URL = 'https://api.deepseek.com/v1/chat/completions'

// é»˜è®¤AIé…ç½®å‚æ•°
export const DEFAULT_CONFIG: AIConfig = {
  v3Config: {
    temperature: 1.0,    // åˆ›é€ æ€§å‚æ•°ï¼Œè¶Šé«˜è¶Šåˆ›æ–°
    maxTokens: 8000      // æœ€å¤§è¾“å‡ºé•¿åº¦ - V3æ¨¡å¼é™åˆ¶ä¸º8K
  },
  r1Config: {
    maxTokens: 32000     // R1æ¨¡å¼æœ€å¤§è¾“å‡ºé•¿åº¦ - R1æ¨¡å¼é»˜è®¤32Kï¼Œæœ€å¤§64K
  },
  showThinking: true,    // æ˜¯å¦æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹
  apiKey: ''            // ç”¨æˆ·è‡ªå®šä¹‰APIå¯†é’¥
}

/**
 * æ„å»ºAPIè¯·æ±‚æ¶ˆæ¯åˆ—è¡¨
 * è¿‡æ»¤æ‰ç³»ç»Ÿä¸éœ€è¦çš„æ¶ˆæ¯ç±»å‹ï¼Œæ·»åŠ ç³»ç»Ÿæç¤º
 * ä¸ºäº†èŠ‚çº¦tokensï¼Œåªä¿ç•™æœ€è¿‘10æ¡å¯¹è¯ä½œä¸ºå†å²
 * @param messages åŸå§‹æ¶ˆæ¯åˆ—è¡¨
 */
function buildMessages(messages: FlatMessage[]): Array<{ role: string; content: string }> {
  const currentDate = new Date().toLocaleDateString('zh-CN', {
    month: 'long',
    day: 'numeric',
    weekday: 'long'
  })
  
  const systemPrompt = `è¯¥åŠ©æ‰‹ä¸ºDeepSeek Chatï¼Œç”±æ·±åº¦æ±‚ç´¢å…¬å¸åˆ›é€ ã€‚\nä»Šå¤©æ˜¯${currentDate}ã€‚`
  
  // å¤„ç†æ¶ˆæ¯ï¼Œä»…ä¿ç•™ç”¨æˆ·å’ŒåŠ©æ‰‹æ¶ˆæ¯
  const allProcessedMessages = messages
    .filter(m => m.role === 'user' || m.role === 'assistant')
    .map(m => ({ role: m.role, content: m.content }))
  
  // åªä¿ç•™æœ€è¿‘10æ¬¡å¯¹è¯ï¼ˆ20æ¡æ¶ˆæ¯ï¼š10ä¸ªç”¨æˆ·+10ä¸ªåŠ©æ‰‹ï¼Œä¸ºäº†èŠ‚çº¦tokensï¼‰
  const recentMessages = allProcessedMessages.slice(-20)
  
  const finalMessages = [
    { role: 'system', content: systemPrompt },
    ...recentMessages
  ]
  
  return finalMessages
}

/**
 * æ„å»ºå®Œæ•´çš„APIè¯·æ±‚ä½“
 * æ ¹æ®ä¸åŒæ¨¡å¼è®¾ç½®ä¸åŒå‚æ•°
 */
function buildRequestBody(
  messages: FlatMessage[], 
  currentMode: ChatMode, 
  config: AIConfig
): Record<string, any> {
  const model = currentMode === 'r1' ? 'deepseek-reasoner' : 'deepseek-chat'
  const modelConfig = currentMode === 'r1' ? config.r1Config : config.v3Config
  
  const requestBody = {
    model,
    messages: buildMessages(messages),
    max_tokens: modelConfig.maxTokens,
    stream: true    // å¯ç”¨æµå¼å“åº”
  }

  // V3æ¨¡å¼æ·»åŠ temperatureå‚æ•°ï¼ŒR1æ¨¡å¼ä¸æ”¯æŒ
  if (currentMode === 'v3') {
    return { ...requestBody, temperature: config.v3Config.temperature }
  }

  return requestBody
}

/**
 * è§£ææµå¼å“åº”æ•°æ®å—
 * å¤„ç† Server-Sent Events æ ¼å¼çš„æ•°æ®
 */
function parseStreamChunk(chunk: string): Array<{ reasoning_content?: string; content?: string }> {
  return chunk.split('\n')
    .filter(line => line.startsWith('data: '))
    .map(line => line.slice(6).trim())
    .filter(data => data !== '[DONE]')
    .map(data => {
      try {
        const parsed: DeepSeekStreamResponse = JSON.parse(data)
        return parsed.choices[0]?.delta || {}
      } catch {
        return {}
      }
    })
    .filter(delta => delta.reasoning_content || delta.content)
}

/**
 * è°ƒç”¨DeepSeek APIçš„ä¸»å‡½æ•°
 * æ”¯æŒæµå¼å“åº”å’Œä¸­æ–­æ§åˆ¶
 */
export async function callDeepSeekAPI(
  messages: FlatMessage[],
  currentMode: ChatMode,
  config: AIConfig,
  abortSignal: AbortSignal,
  onThinkingUpdate: (thinking: string) => void,
  onAnswerUpdate: (answer: string) => void
): Promise<{ reasoning_content?: string; content: string }> {
  
  const requestBody = buildRequestBody(messages, currentMode, config)
  
  // ç›´æ¥è¾“å‡ºå‘é€çš„æ¶ˆæ¯å†…å®¹
  console.log('ğŸ“¤ å‘é€ç»™APIçš„æ¶ˆæ¯:', JSON.stringify(requestBody.messages, null, 2))
  
  const response = await fetch(API_BASE_URL, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${config.apiKey}`
    },
    body: JSON.stringify(requestBody),
    signal: abortSignal
  })

  if (!response.ok) {
    throw new Error(`API è¯·æ±‚å¤±è´¥: ${response.status}`)
  }

  const reader = response.body?.getReader()
  if (!reader) throw new Error('æ— æ³•è·å–å“åº”æµ')

  let reasoning_content = ''  // R1æ¨¡å¼çš„æ€è€ƒè¿‡ç¨‹
  let content = ''           // æœ€ç»ˆå›ç­”å†…å®¹

  try {
    // æŒç»­è¯»å–æµå¼æ•°æ®
    while (true) {
      const { done, value } = await reader.read()
      if (done) break

      const deltas = parseStreamChunk(new TextDecoder().decode(value))
      for (const delta of deltas) {
        if (delta.reasoning_content) {
          reasoning_content += delta.reasoning_content
          onThinkingUpdate(reasoning_content)  // å®æ—¶æ›´æ–°æ€è€ƒè¿‡ç¨‹
        }
        if (delta.content) {
          content += delta.content
          onAnswerUpdate(content)  // å®æ—¶æ›´æ–°å›ç­”å†…å®¹
        }
      }
    }
  } finally {
    reader.releaseLock()
  }

  return {
    reasoning_content: reasoning_content || undefined,
    content: content || 'æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ç†è§£æ‚¨çš„é—®é¢˜ã€‚'
  }
} 